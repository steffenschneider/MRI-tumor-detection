{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steffenschneider/MRI-tumor-detection/blob/main/mri_tumor_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaQTt8Nhkny7"
      },
      "source": [
        "# import libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWxHYA3Zi-TQ",
        "outputId": "c1f071d5-f89e-436c-e3eb-252a4d9198a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Steffen\n"
          ]
        }
      ],
      "source": [
        "# !pip install tensorflow\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras import layers, metrics, callbacks, applications, regularizers\n",
        "from keras.regularizers import l2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZL56gPmskKG"
      },
      "source": [
        "# get data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "paFczMGc1q6I",
        "outputId": "3285ed2c-768c-484e-e856-0ec2623b5e70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nif not os.path.exists(\\'/content\\'):\\n    os.makedirs(\\'/content\\')\\n\\nimport shutil\\n#shutil.rmtree(\\'\\')\\n\\nfrom google.colab import files\\nuploaded = files.upload()       # choose zip folder manually\\n\\ndata_dir = \"./mri-tumor\"  # contains \"yes\" and \"no\" folders\\n\\nimport zipfile\\nwith zipfile.ZipFile(\\'mri-data.zip\\', \\'r\\') as zip_ref:\\n    zip_ref.extractall(data_dir)\\n\\nshutil.rmtree(data_dir + \\'/brain_tumor_dataset\\')    # delete additional redundant files\\n'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_dir = \"C:/Users/Steffen/kaggle/mri-data\"\n",
        "\n",
        "# for use in Google Colab\n",
        "'''\n",
        "if not os.path.exists('/content'):\n",
        "    os.makedirs('/content')\n",
        "\n",
        "import shutil\n",
        "#shutil.rmtree('')\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()       # choose zip folder manually\n",
        "\n",
        "data_dir = \"./mri-tumor\"  # contains \"yes\" and \"no\" folders\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile('mri-data.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall(data_dir)\n",
        "\n",
        "shutil.rmtree(data_dir + '/brain_tumor_dataset')    # delete additional redundant files\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82jgpi7o5WBx"
      },
      "source": [
        "# split data into training and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aB9SGjhFrq83",
        "outputId": "b88bedbf-71a3-42c4-8c4b-0e689b825961"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 253 files belonging to 2 classes.\n",
            "Using 203 files for training.\n",
            "Found 253 files belonging to 2 classes.\n",
            "Using 50 files for validation.\n",
            "Sum of data / pictures: 25\n"
          ]
        }
      ],
      "source": [
        "img_size = (224, 224)  # ResNet50 requires 224x224\n",
        "batch_size = 25\n",
        "\n",
        "# First split: 80% train, 20% validation and test\n",
        "# color_mode=\"rgb\" is needed for ResNet50, which expects 3 channels\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    labels='inferred',\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=42,\n",
        "    image_size=img_size,        # image is resized here\n",
        "    batch_size=batch_size,\n",
        "    color_mode=\"rgb\"\n",
        ")\n",
        "\n",
        "# color_mode=\"rgb\" is needed for ResNet50, which expects 3 channels\n",
        "temp_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    labels='inferred',\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=42,\n",
        "    image_size=img_size,        # image is resized here\n",
        "    batch_size=batch_size,\n",
        "    color_mode=\"rgb\"\n",
        ")\n",
        "\n",
        "# Second split: Split temp into 50% validation, 50% test (10% each of original)\n",
        "n_batches = 1\n",
        "val_ds = temp_ds.take(n_batches)     # 25 pictures for validation\n",
        "test_ds = temp_ds.skip(n_batches)    # 25 pictures for testing\n",
        "\n",
        "data_count = 0\n",
        "for batch in test_ds:\n",
        "    images, labels = batch\n",
        "    data_count += len(images)\n",
        "print(f\"Sum of data / pictures: {data_count}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ug5r0zg56GCM"
      },
      "source": [
        "# augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fcFvRiIY6FTR"
      },
      "outputs": [],
      "source": [
        "# AUGMENTATION\n",
        "# no new images are created, only the original images are augmented\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomZoom(0.2),\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomBrightness(0.2)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrRc1rGV6T65"
      },
      "source": [
        "# normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "pwv_tKvH6OkC",
        "outputId": "c263eda0-3cc7-4d24-dc4f-773741c8b459"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\ndata_count = 0\\nfor batch in test_ds:\\n    images, labels = batch\\n    print(images[0][0][0])      # tf.Tensor([0.3997549 0.3997549 0.3997549], shape=(3,), dtype=float32)\\n'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# NORMALIZATION\n",
        "# Normalize the images to [0,1] range\n",
        "# ResNet50 expects images in the range [-1,1]\n",
        "def preprocess(image, label):\n",
        "    image = data_augmentation(image)\n",
        "    #image = tf.keras.applications.resnet50.preprocess_input(image)  # Normalize images, DOES NOT WORK!!!\n",
        "    image = image / 255.0  # Scale pixel values to [0, 1]\n",
        "    return image, label\n",
        "\n",
        "train_ds = train_ds.map(preprocess)\n",
        "val_ds = val_ds.map(preprocess)\n",
        "test_ds = test_ds.map(preprocess)\n",
        "\n",
        "'''\n",
        "data_count = 0\n",
        "for batch in test_ds:\n",
        "    images, labels = batch\n",
        "    print(images[0][0][0])      # tf.Tensor([0.3997549 0.3997549 0.3997549], shape=(3,), dtype=float32)\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXDHJsyH6e0f"
      },
      "source": [
        "# build and compile model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jmIYQfwx6N2X"
      },
      "outputs": [],
      "source": [
        "\n",
        "# MODEL\n",
        "# ResNet50 as feature extractor\n",
        "# use ResNet50V2 with ImageNet weights - pre-trained model!\n",
        "# V2 with better accuracy!\n",
        "# only two output classes: \"yes\" and \"no\"\n",
        "base_model = keras.applications.ResNet50V2(\n",
        "    include_top=False,              # use my own input layer and output layer\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(224, 224, 3),      # ResNet50V2 needs 3 channels\n",
        "    classes=2,\n",
        "    name=\"resnet50v2\",\n",
        ")\n",
        "\n",
        "# use trainable = False if < 10.000 images (avoids overfitting)\n",
        "base_model.trainable = False  # Freeze the base model\n",
        "\n",
        "# BUILDING THE MODEL\n",
        "# Why sigmoid? Because we have only two classes (binary classification)\n",
        "model = keras.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation=\"relu\", kernel_regularizer=l2(0.001)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.6),\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.6),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# COMPILE MODEL\n",
        "# Adam optimizer is often the best choice for transfer learning\n",
        "# use binary_crossentropy for binary classification\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.00008),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\n",
        "        \"accuracy\",                # Genauigkeit (Accuracy)\n",
        "        metrics.Precision(),       # Präzision\n",
        "        metrics.Recall()           # Recall (Sensitivität)\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGmN5KLt6p3V"
      },
      "source": [
        "# class weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpdDu0mg6kei",
        "outputId": "523ff164-b335-423e-d4ef-47b93362bc56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "amount of no-files: 98\n",
            "amount of yes-files: 155\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# CLASS WEIGHTS\n",
        "# Calculate class weights to balance the dataset\n",
        "# n_yes = 155\n",
        "# n_no = 98\n",
        "dir_no = os.path.join(data_dir, 'no')\n",
        "n_no = len(os.listdir(dir_no))\n",
        "print(f\"amount of no-files: {n_no}\")\n",
        "\n",
        "dir_yes = os.path.join(data_dir, 'yes')\n",
        "n_yes = len(os.listdir(dir_yes))\n",
        "print(f\"amount of yes-files: {n_yes}\")\n",
        "\n",
        "ratio = n_yes / n_no\n",
        "class_weights = {0: ratio, 1: 1.0}  # ratio is 1.6207...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dooSYas64aB"
      },
      "source": [
        "# model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK5qCSUX63OL",
        "outputId": "1c1fca0f-f376-405f-c055-fa43de3e469b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.7231 - loss: 0.9777 - precision_2: 0.8114 - recall_2: 0.7306 - val_accuracy: 0.8400 - val_loss: 0.5834 - val_precision_2: 0.9286 - val_recall_2: 0.8125\n",
            "Epoch 2/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.7715 - loss: 0.9204 - precision_2: 0.8542 - recall_2: 0.7625 - val_accuracy: 0.8400 - val_loss: 0.6121 - val_precision_2: 0.9375 - val_recall_2: 0.8333\n",
            "Epoch 3/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.6703 - loss: 1.0520 - precision_2: 0.7329 - recall_2: 0.6708 - val_accuracy: 0.8800 - val_loss: 0.6674 - val_precision_2: 1.0000 - val_recall_2: 0.8333\n",
            "Epoch 4/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.6208 - loss: 1.1232 - precision_2: 0.7432 - recall_2: 0.6185 - val_accuracy: 0.8000 - val_loss: 0.6286 - val_precision_2: 0.8667 - val_recall_2: 0.8125\n",
            "Epoch 5/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.6816 - loss: 1.0695 - precision_2: 0.8081 - recall_2: 0.6290 - val_accuracy: 0.8800 - val_loss: 0.6546 - val_precision_2: 0.9167 - val_recall_2: 0.8462\n",
            "Epoch 6/100\n",
            "\u001b[1m3/9\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.6444 - loss: 1.0329 - precision_2: 0.7708 - recall_2: 0.6055"
          ]
        }
      ],
      "source": [
        "# TRAINING\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    min_delta=0.001,\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=100,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[early_stopping]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55hDnVRc7G5s"
      },
      "source": [
        "# evaluation + confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wQQJX5r07Blo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8400 - loss: 0.6032 - precision_2: 0.8750 - recall_2: 0.8750\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 2)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# EVALUATION\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_ds)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Plot accuracy and loss curves\u001b[39;00m\n",
            "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ],
      "source": [
        "\n",
        "# EVALUATION\n",
        "test_loss, test_acc = model.evaluate(test_ds)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Plot accuracy and loss curves\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
        "plt.plot(history.history[\"val_accuracy\"], label=\"Val Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# PREDICTION\n",
        "y_val = []\n",
        "y_val_pred = []\n",
        "for images, labels in val_ds:\n",
        "    print(images.shape)\n",
        "    print(labels.shape)\n",
        "    y_val.extend(labels)\n",
        "    y_val_pred.extend(model.predict(images))\n",
        "\n",
        "# Confusion Matrix validation\n",
        "cm = confusion_matrix(y_val, np.round(y_val_pred))\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "y_test = []\n",
        "y_test_pred = []\n",
        "for images, labels in test_ds:\n",
        "    print(images.shape)\n",
        "    print(labels.shape)\n",
        "    y_test.extend(labels)\n",
        "    y_test_pred.extend(model.predict(images))\n",
        "\n",
        "# Confusion Matrix test\n",
        "cm = confusion_matrix(y_test, np.round(y_test_pred))\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPHKKIBQhbHiYeO+w3mhAMh",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

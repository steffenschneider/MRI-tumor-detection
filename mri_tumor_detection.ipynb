{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjKhGN/d0RSI37/lyBS9sX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steffenschneider/MRI-tumor-detection/blob/main/mri_tumor_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries\n"
      ],
      "metadata": {
        "id": "ZaQTt8Nhkny7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWxHYA3Zi-TQ",
        "outputId": "2ecedb23-1302-4d5d-eded-980e5bc790d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.18.0\n"
          ]
        }
      ],
      "source": [
        "# !pip install tensorflow\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neuer Abschnitt"
      ],
      "metadata": {
        "id": "MO5mDIC-qMoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set data directory\n",
        "data_dir = \"./braintumor\"  # Contains \"yes\" and \"no\" folders\n",
        "img_size = (224, 224)  # ResNet50 requires 224x224\n",
        "batch_size = 25\n",
        "\n",
        "# First split: 80% train, 20% validation and test\n",
        "# color_mode=\"rgb\" is needed for ResNet50, which expects 3 channels\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    labels='inferred',\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=42,\n",
        "    image_size=img_size,        # image is resized here\n",
        "    batch_size=batch_size,\n",
        "    color_mode=\"rgb\"\n",
        ")\n",
        "\n",
        "# color_mode=\"rgb\" is needed for ResNet50, which expects 3 channels\n",
        "temp_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    labels='inferred',\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=42,\n",
        "    image_size=img_size,        # image is resized here\n",
        "    batch_size=batch_size,\n",
        "    color_mode=\"rgb\"\n",
        ")\n",
        "\n",
        "# Second split: Split temp into 50% validation, 50% test (10% each of original)\n",
        "n_batches = 1\n",
        "val_ds = temp_ds.take(n_batches)     # 25 pictures for validation\n",
        "test_ds = temp_ds.skip(n_batches)    # 25 pictures for testing\n",
        "\n",
        "'''''\n",
        "data_count = 0\n",
        "for batch in test_ds:\n",
        "    images, labels = batch\n",
        "    data_count += len(images)\n",
        "print(f\"Sum of data / pictures: {data_count}\")\n",
        "'''\n",
        "\n",
        "# AUGMENTATION\n",
        "# no new images are created, only the original images are augmented\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomZoom(0.2),\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomBrightness(0.2)\n",
        "])\n",
        "\n",
        "# NORMALIZATION\n",
        "# Normalize the images to [0,1] range\n",
        "# ResNet50 expects images in the range [-1,1]\n",
        "def preprocess(image, label):\n",
        "    image = data_augmentation(image)\n",
        "    #image = tf.keras.applications.resnet50.preprocess_input(image)  # Normalize images, DOES NOT WORK!!!\n",
        "    image = image / 255.0  # Scale pixel values to [0, 1]\n",
        "    return image, label\n",
        "\n",
        "train_ds = train_ds.map(preprocess)\n",
        "val_ds = val_ds.map(preprocess)\n",
        "test_ds = test_ds.map(preprocess)\n",
        "\n",
        "'''\n",
        "data_count = 0\n",
        "for batch in test_ds:\n",
        "    images, labels = batch\n",
        "    print(images[0][0][0])      # tf.Tensor([0.3997549 0.3997549 0.3997549], shape=(3,), dtype=float32)\n",
        "'''\n",
        "\n",
        "# MODEL\n",
        "# ResNet50 as feature extractor\n",
        "# use ResNet50V2 with ImageNet weights - pre-trained model!\n",
        "# V2 with better accuracy!\n",
        "# only two output classes: \"yes\" and \"no\"\n",
        "base_model = keras.applications.ResNet50V2(\n",
        "    include_top=False,              # use my own input layer and output layer\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(224, 224, 3),      # ResNet50V2 needs 3 channels\n",
        "    classes=2,\n",
        "    name=\"resnet50v2\",\n",
        ")\n",
        "\n",
        "# use trainable = False if < 10.000 images (avoids overfitting)\n",
        "base_model.trainable = False  # Freeze the base model\n",
        "\n",
        "# BUILDING THE MODEL\n",
        "# Why sigmoid? Because we have only two classes (binary classification)\n",
        "model = keras.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation=\"relu\", kernel_regularizer=l2(0.001)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.6),\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.6),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# COMPILE MODEL\n",
        "# Adam optimizer is often the best choice for transfer learning\n",
        "# use binary_crossentropy for binary classification\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.00003),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\n",
        "        \"accuracy\",                # Genauigkeit (Accuracy)\n",
        "        metrics.Precision(),       # Präzision\n",
        "        metrics.Recall()           # Recall (Sensitivität)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# CLASS WEIGHTS\n",
        "# Calculate class weights to balance the dataset\n",
        "# n_yes = 155\n",
        "# n_no = 98\n",
        "# Done - change numbers if pictures are deleted. Better use not hardcoded numbers\n",
        "dir_no = os.path.join(data_dir, 'no')\n",
        "n_no = len(os.listdir(dir_no))\n",
        "print(f\"amount of no-files: {n_no}\")\n",
        "\n",
        "dir_yes = os.path.join(data_dir, 'yes')\n",
        "n_yes = len(os.listdir(dir_yes))\n",
        "print(f\"amount of yes-files: {n_yes}\")\n",
        "\n",
        "ratio = n_yes / n_no\n",
        "class_weights = {0: ratio, 1: 1.0}  # ratio is 1.6207...\n",
        "\n",
        "# TRAINING\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    min_delta=0.001,\n",
        "    patience=15,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=20,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# EVALUATION\n",
        "test_loss, test_acc = model.evaluate(test_ds)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Plot accuracy and loss curves\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
        "plt.plot(history.history[\"val_accuracy\"], label=\"Val Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# PREDICTION\n",
        "y_val = []\n",
        "y_val_pred = []\n",
        "for images, labels in val_ds:\n",
        "    print(images.shape)\n",
        "    print(labels.shape)\n",
        "    y_val.extend(labels)\n",
        "    # y_val_pred.extend(model.predict(images, verbose=True, batch_size=16))\n",
        "    y_val_pred.extend(model.predict(images))\n",
        "\n",
        "# Confusion Matrix validation\n",
        "cm = confusion_matrix(y_val, np.round(y_val_pred))\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "y_test = []\n",
        "y_test_pred = []\n",
        "for images, labels in test_ds:\n",
        "    print(images.shape)\n",
        "    print(labels.shape)\n",
        "    y_test.extend(labels)\n",
        "    y_test_pred.extend(model.predict(images))\n",
        "\n",
        "# Confusion Matrix test\n",
        "cm = confusion_matrix(y_test, np.round(y_test_pred))\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "ExCWDrjPkkCs",
        "outputId": "38d46874-e4d6-4cfa-fdea-9ebc2e6193e1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "Could not find directory ./braintumor",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-282db65a2fe0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# First split: 80% train, 20% validation and test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# color_mode=\"rgb\" is needed for ResNet50, which expects 3 channels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m train_ds = tf.keras.utils.image_dataset_from_directory(\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inferred'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/image_dataset_utils.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, pad_to_aspect_ratio, data_format, verbose)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m     image_paths, labels, class_names = dataset_utils.index_directory(\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/dataset_utils.py\u001b[0m in \u001b[0;36mindex_directory\u001b[0;34m(directory, labels, formats, class_names, shuffle, seed, follow_links, verbose)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"inferred\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0msubdirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mlist_directory_v2\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    766\u001b[0m   \"\"\"\n\u001b[1;32m    767\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m     raise errors.NotFoundError(\n\u001b[0m\u001b[1;32m    769\u001b[0m         \u001b[0mnode_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0mop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Could not find directory ./braintumor"
          ]
        }
      ]
    }
  ]
}